@inproceedings{chinnappa-etal-2019-extracting,
    title = "Extracting Possessions from Social Media: Images Complement Language",
    author = "Chinnappa, Dhivya  and
      Murugan, Srikala  and
      Blanco, Eduardo",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1061",
    doi = "10.18653/v1/D19-1061",
    pages = "663--672",
    abstract = "This paper describes a new dataset and experiments to determine whether authors of tweets possess the objects they tweet about. We work with 5,000 tweets and show that both humans and neural networks benefit from images in addition to text. We also introduce a simple yet effective strategy to incorporate visual information into any neural network beyond weights from pretrained networks. Specifically, we consider the tags identified in an image as an additional textual input, and leverage pretrained word embeddings as usually done with regular text. Experimental results show this novel strategy is beneficial.",
}
